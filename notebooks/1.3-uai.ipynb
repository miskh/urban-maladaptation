{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9326a14f",
   "metadata": {},
   "source": [
    "# Urban (mal)adaptation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858734d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from utils import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "matplotlib.rcParams['figure.dpi'] = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febc697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_formats = ['svg', 'eps', 'pdf', 'png']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aab7f3",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load district shapefile\n",
    "districts_shapefile = gpd.read_file('../data/processed/cbs/wijk_buurt_kaart/districts.json')\n",
    "\n",
    "# Define number of runs to load\n",
    "n_runs = 10\n",
    "\n",
    "# Function to process scenario data\n",
    "def process_scenario(scenario_name, n_runs):\n",
    "    \"\"\"Process infection data for a given scenario\"\"\"\n",
    "    \n",
    "    # List all files corresponding to experimental setup\n",
    "    file_paths = find_files(f'../results/{scenario_name}', 'infectedPersons.csv')\n",
    "    print(f\"\\n{scenario_name.upper()} - Number of experiments: {len(file_paths)}\")\n",
    "    \n",
    "    # Extract experiment names\n",
    "    experiment_names = [os.path.basename(os.path.dirname(\n",
    "        file_path)) for file_path in file_paths][:n_runs]\n",
    "    \n",
    "    # Store start and end dates to find the smallest and largest\n",
    "    start_end_dates = {}\n",
    "    \n",
    "    print(f'Loading {scenario_name} experiment results...')\n",
    "    for experiment_name, file_path in tqdm(zip(experiment_names, file_paths[:n_runs]), total=n_runs):\n",
    "        # Load experiment results\n",
    "        results = pd.read_csv(file_path)\n",
    "        \n",
    "        # Add date_time column\n",
    "        results['date_time'] = results['Time(h)'].apply(lambda x: relativedelta(\n",
    "            years=50, months=2) + datetime.datetime(*time.gmtime(x * 3600)[:6]))\n",
    "        \n",
    "        # Get the start and end dates of the experiment\n",
    "        experiment_start = results['date_time'].min().date()\n",
    "        experiment_end = results['date_time'].max().date()\n",
    "        \n",
    "        # Store start and end dates\n",
    "        start_end_dates[experiment_name] = (experiment_start, experiment_end)\n",
    "    \n",
    "    # Find the smallest and largest start and end dates\n",
    "    min_start = min(start for start, _ in start_end_dates.values())\n",
    "    max_end = max(end for _, end in start_end_dates.values())\n",
    "    print(f\"Max date: {max_end}\")\n",
    "    print(f\"Min date: {min_start}\")\n",
    "    \n",
    "    print(f\"Smallest start date: {min_start}\")\n",
    "    print(f\"Largest end date: {max_end}\")\n",
    "    \n",
    "    # Define complete dates\n",
    "    complete_dates = pd.date_range(start=min_start, end=max_end, freq='d')\n",
    "    \n",
    "    # Store infections in dictionaries\n",
    "    all_infections = {}\n",
    "    infections_by_day = {}\n",
    "    district_infections_by_day = {}\n",
    "    resident_visitor_infections_by_day = {}\n",
    "    district_resident_visitor_infections_by_day = {}\n",
    "    district_resident_visitor_infections_by_day_location = {}\n",
    "    \n",
    "    # Process each file\n",
    "    print(f'Processing {scenario_name} infections...')\n",
    "    for experiment_name, file_path in tqdm(zip(experiment_names, file_paths[:n_runs]), total=n_runs):\n",
    "        # Load experiment results\n",
    "        results = pd.read_csv(file_path)\n",
    "        \n",
    "        # Convert to GeoDataFrame with infection location as geometry\n",
    "        results = gpd.GeoDataFrame(results, geometry=gpd.points_from_xy(\n",
    "            results['infectLocationLon'], results['infectLocationLat']))\n",
    "        \n",
    "        # Add date_time column\n",
    "        results['date_time'] = results['Time(h)'].apply(lambda x: relativedelta(\n",
    "            years=50, months=2) + datetime.datetime(*time.gmtime(x * 3600)[:6]))\n",
    "        \n",
    "        # Add residence and infection districts to the data\n",
    "        results = results.pipe(assign_residence_district, districts_shapefile)\\\n",
    "                         .pipe(assign_infection_district, districts_shapefile)\n",
    "        \n",
    "        # Add dummy variable indicating infection\n",
    "        results['infection'] = 1\n",
    "        \n",
    "        # Add infection_type column based on whether infection occurred in district of residence\n",
    "        results['infection_type'] = 'Visitor'  # Default to visitor\n",
    "        \n",
    "        # If infection district matches residence district, mark as resident\n",
    "        mask = results['infection_district_name'] == results['residence_district_name']\n",
    "        results.loc[mask, 'infection_type'] = 'Resident'\n",
    "        \n",
    "        # 1. Store all results\n",
    "        all_infections[experiment_name] = results\n",
    "        \n",
    "        # 2. CALCULATE INFECTIONS BY DAY\n",
    "        results_grouped = results.groupby(results['date_time'].dt.date)['infection'].sum()\n",
    "        results_grouped = results_grouped.reindex(complete_dates, fill_value=0)\n",
    "        infections_by_day[experiment_name] = results_grouped\n",
    "        \n",
    "        # 3. DIFFERENTIATE BETWEEN INFECTIONS OF RESIDENTS AND VISITORS\n",
    "        results_grouped = results.groupby(['infection_type', results['date_time'].dt.date])['infection'].sum()\n",
    "        results_grouped = results_grouped.unstack(level=0)\n",
    "        results_grouped = results_grouped.reindex(complete_dates, fill_value=0)\n",
    "        results_grouped = results_grouped.stack().swaplevel(0, 1).sort_index()\n",
    "        resident_visitor_infections_by_day[experiment_name] = results_grouped\n",
    "        \n",
    "        # 4. CALCULATE INFECTIONS BY DAY FOR THE DISTRICTS OF INTEREST\n",
    "        results_grouped = results.groupby(['infection_district_name', results['date_time'].dt.date])['infection'].sum()\n",
    "        results_grouped = results_grouped.unstack(level=0)\n",
    "        results_grouped = results_grouped.reindex(complete_dates, fill_value=0)\n",
    "        results_grouped = results_grouped.stack().swaplevel(0, 1).sort_index()\n",
    "        district_infections_by_day[experiment_name] = results_grouped\n",
    "        \n",
    "        # 5. CALCULATE INFECTIONS BY TYPE AND DISTRICT\n",
    "        results_grouped = results.groupby(['infection_district_name', 'infection_type', \n",
    "                                          results['date_time'].dt.date])['infection'].sum()\n",
    "        results_grouped = results_grouped.unstack(level=2)\n",
    "        results_grouped = results_grouped.reindex(columns=complete_dates, fill_value=0)\n",
    "        results_grouped = results_grouped.stack()\n",
    "        district_resident_visitor_infections_by_day[experiment_name] = results_grouped\n",
    "        \n",
    "        # 6. INFECTIONS BY LOCATION AND TYPE AND DISTRICT\n",
    "        results_grouped = results.groupby(['infection_district_name', 'infection_type',\n",
    "                                          'infectLocationType', results['date_time'].dt.date])['infection'].sum()\n",
    "        results_grouped = results_grouped.unstack(level=3)\n",
    "        results_grouped = results_grouped.reindex(columns=complete_dates, fill_value=0)\n",
    "        results_grouped = results_grouped.stack()\n",
    "        district_resident_visitor_infections_by_day_location[experiment_name] = results_grouped\n",
    "    \n",
    "    # Concatenate all results\n",
    "    infections_by_day_df = pd.concat(infections_by_day.values(), axis=1)\n",
    "    infections_by_day_df.columns = experiment_names\n",
    "    \n",
    "    resident_visitor_infections_by_day_df = pd.concat(resident_visitor_infections_by_day.values(), axis=1)\n",
    "    resident_visitor_infections_by_day_df.columns = experiment_names\n",
    "    \n",
    "    district_infections_by_day_df = pd.concat(district_infections_by_day.values(), axis=1)\n",
    "    district_infections_by_day_df.columns = experiment_names\n",
    "    \n",
    "    district_resident_visitor_infections_by_day_df = pd.concat(district_resident_visitor_infections_by_day.values(), axis=1)\n",
    "    district_resident_visitor_infections_by_day_df.columns = experiment_names\n",
    "    \n",
    "    district_resident_visitor_infections_by_day_location_df = pd.concat(district_resident_visitor_infections_by_day_location.values(), axis=1)\n",
    "    district_resident_visitor_infections_by_day_location_df.columns = experiment_names\n",
    "    \n",
    "    return {\n",
    "        'all_infections': all_infections,\n",
    "        'infections_by_day': infections_by_day_df,\n",
    "        'resident_visitor_infections_by_day': resident_visitor_infections_by_day_df,\n",
    "        'district_infections_by_day': district_infections_by_day_df,\n",
    "        'district_resident_visitor_infections_by_day': district_resident_visitor_infections_by_day_df,\n",
    "        'district_resident_visitor_infections_by_day_location': district_resident_visitor_infections_by_day_location_df\n",
    "    }\n",
    "\n",
    "# Process both scenarios\n",
    "baseline_results = process_scenario('baseline', n_runs)\n",
    "maladaptation_results = process_scenario('lockdown', n_runs)\n",
    "\n",
    "# Extract results for baseline\n",
    "all_infections_baseline = baseline_results['all_infections'].copy() \n",
    "infections_by_day_baseline = baseline_results['infections_by_day'].copy()\n",
    "resident_visitor_infections_by_day_baseline = baseline_results[\n",
    "    'resident_visitor_infections_by_day'].copy()\n",
    "district_infections_by_day_baseline = baseline_results['district_infections_by_day'].copy()\n",
    "district_resident_visitor_infections_by_day_baseline = baseline_results[\n",
    "    'district_resident_visitor_infections_by_day'].copy()\n",
    "district_resident_visitor_infections_by_day_location_baseline = baseline_results[\n",
    "    'district_resident_visitor_infections_by_day_location'].copy()\n",
    "\n",
    "# Extract results for maladaptation\n",
    "all_infections_maladaptation = maladaptation_results['all_infections'].copy()\n",
    "infections_by_day_maladaptation = maladaptation_results['infections_by_day'].copy()\n",
    "resident_visitor_infections_by_day_maladaptation = maladaptation_results[\n",
    "    'resident_visitor_infections_by_day'].copy()\n",
    "district_infections_by_day_maladaptation = maladaptation_results['district_infections_by_day'].copy()\n",
    "district_resident_visitor_infections_by_day_maladaptation = maladaptation_results[\n",
    "    'district_resident_visitor_infections_by_day'].copy()\n",
    "district_resident_visitor_infections_by_day_location_maladaptation = maladaptation_results[\n",
    "    'district_resident_visitor_infections_by_day_location'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24571d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "central_color = '#FF5C00'\n",
    "outer_color = '#00CAB1'\n",
    "\n",
    "def district_daily_totals(df: pd.DataFrame,\n",
    "                           start: str | None = None, end: str | None = None,\n",
    "                           agg: str = \"mean\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns date×district totals aggregated over runs.\n",
    "    agg: 'mean' (default) or 'median'\n",
    "    \"\"\"\n",
    "    df.index = df.index.set_levels(pd.to_datetime(df.index.levels[1]), level=1)\n",
    "    df = df.sort_index()\n",
    "\n",
    "    # Optional window\n",
    "    if start or end:\n",
    "        df = df.loc[pd.IndexSlice[:, slice(pd.to_datetime(start) if start else None,\n",
    "                                             pd.to_datetime(end) if end else None)], :]\n",
    "\n",
    "    # Aggregate over runs per (district,date)\n",
    "    if agg == \"mean\":\n",
    "        totals = df.mean(axis=1, skipna=True)\n",
    "    elif agg == \"median\":\n",
    "        totals = df.median(axis=1, skipna=True)\n",
    "    else:\n",
    "        raise ValueError(\"agg must be 'mean', 'median', or 'sum'.\")\n",
    "\n",
    "    totals = totals.unstack(level=0).sort_index()  # date × district\n",
    "    return totals.fillna(0.0)\n",
    "\n",
    "def shares_from_totals(totals: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Row-normalize totals to shares per day (safe divide).\"\"\"\n",
    "    row_sum = totals.sum(axis=1).replace(0, np.nan)\n",
    "    shares = totals.div(row_sum, axis=0).fillna(0.0)\n",
    "    return shares\n",
    "\n",
    "# ---------- 2) Ranks and rank changes over time ----------\n",
    "def rank_change_over_time(df_baseline: pd.DataFrame,\n",
    "                          df_policy: pd.DataFrame,\n",
    "                          use_shares: bool = False,\n",
    "                          start: str | None = None,\n",
    "                          end: str | None = None):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      dates, shares_b (date×district), shares_p, ranks_b, ranks_p, delta_rank (date×district), delta_rank_cum\n",
    "    \"\"\"\n",
    "    Tb = district_daily_totals(df_baseline, start, end)\n",
    "    Tp = district_daily_totals(df_policy,   start, end)\n",
    "\n",
    "    # align on dates and districts\n",
    "    Tb, Tp = Tb.align(Tp, join=\"inner\", axis=0)\n",
    "    Tb, Tp = Tb.align(Tp, join=\"inner\", axis=1)\n",
    "\n",
    "    if use_shares:\n",
    "        sb = shares_from_totals(Tb)\n",
    "        sp = shares_from_totals(Tp)\n",
    "    else:\n",
    "        sb = Tb\n",
    "        sp = Tp\n",
    "\n",
    "    # ranks each day (1 = highest share). 'min' keeps ties stable at best rank.\n",
    "    rb = sb.rank(axis=1, ascending=False, method='min')\n",
    "    rp = sp.rank(axis=1, ascending=False, method='min')\n",
    "\n",
    "    # positive means worsening (moved toward top under policy)\n",
    "    delta_rank = rb - rp\n",
    "    delta_rank_cum = delta_rank.expanding(min_periods=1).mean()\n",
    "\n",
    "    return sb.index, sb, sp, rb, rp, delta_rank, delta_rank_cum\n",
    "\n",
    "def plot_rank(\n",
    "    dates, delta_rank, delta_rank_cum,\n",
    "    focus_districts: list[str],\n",
    "    district_labels: dict[str, str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Rank change (Δrank = r_baseline − r_policy).\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    \n",
    "\n",
    "    for d in focus_districts:\n",
    "        label = district_labels.get(d, d)\n",
    "        color = central_color if label == \"Central\" else outer_color\n",
    "        ax.plot(dates, delta_rank[d], lw=1.2, ls=\"--\", alpha=0.9, color=color, label=f\"{label} Δrank (daily)\")\n",
    "        line = ax.plot(dates, delta_rank_cum[d], lw=2.2, alpha=1.0, color=color, label=f\"{label} Δrank (cum)\")\n",
    "        \n",
    "        # Add annotation for adaptation/maladaptation\n",
    "        if label == \"Central\":\n",
    "            ax.annotate(\"Adaptation\", xy=(dates[-1], delta_rank_cum[d].iloc[-1]),\n",
    "                       xytext=(10, 0), textcoords='offset points',\n",
    "                       fontsize=9, color=color, va='center')\n",
    "        else:\n",
    "            ax.annotate(\"Maladaptation\", xy=(dates[-1], delta_rank_cum[d].iloc[-1]),\n",
    "                       xytext=(10, 0), textcoords='offset points',\n",
    "                       fontsize=9, color=color, va='center')\n",
    "\n",
    "    ax.axhline(0, ls=\"--\", lw=1, color=\"black\", alpha=0.6)\n",
    "    ax.set_xlabel(\"Simulation time (date)\")\n",
    "    ax.set_ylabel(r\"$\\Delta r$ = $r_{\\mathrm{No\\text{-}response}} - r_{\\mathrm{Hard\\ lockdown}}$\")\n",
    "\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b %d\"))\n",
    "    ax.xaxis.set_major_locator(mdates.DayLocator(interval=7))\n",
    "    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha=\"right\")\n",
    "    ax.spines[[\"top\", \"right\"]].set_visible(False)\n",
    "    ax.legend(frameon=False, ncol=1)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "district1 = \"Wijk 28 Centrum\"     # Central\n",
    "district2 = \"Wijk 42 Ypenburg\"    # Outer residential\n",
    "focus = [district1, district2]\n",
    "\n",
    "# Create display labels for the districts\n",
    "district_labels = {\n",
    "    \"Wijk 28 Centrum\": \"Central\",\n",
    "    \"Wijk 42 Ypenburg\": \"Outer residential\"\n",
    "}\n",
    "\n",
    "dates, sb, sp, rb, rp, dr, drcum = rank_change_over_time(\n",
    "    district_infections_by_day_baseline, \n",
    "    district_infections_by_day_maladaptation,\n",
    "    start=None, end=None\n",
    ")\n",
    "\n",
    "plot_rank(dates, dr, drcum, focus, district_labels)\n",
    "for fmt in figure_formats:\n",
    "    plt.savefig(f\"../figures/fig7.{fmt}\", format=fmt, dpi=300, bbox_inches='tight')\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Final_UAI_rank\": drcum.iloc[-1],\n",
    "    \"Initial_rank\": rb.iloc[0],\n",
    "    \"Final_rank\": rp.iloc[-1]\n",
    "}).sort_values(\"Final_UAI_rank\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flippingrisks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
